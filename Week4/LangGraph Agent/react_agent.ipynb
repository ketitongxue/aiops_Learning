{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# React Agent 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U langgraph langchain-openai langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Literal\n",
    "from langchain_core.tools import tool\n",
    "from IPython.display import Image, display\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# LangSmith 项目名称，生成 APIKEY的时候会给\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-gripping-utilisation-66\"\n",
    "\n",
    "@tools\n",
    "def get_deployment(deployment_name: str):\n",
    "    \"\"\"Use this to get deployment YAML.\"\"\"\n",
    "    print(\"get deployment: \", deplyment_name)\n",
    "    return \"\"\"\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: payment\n",
    "spec:\n",
    "    selector:\n",
    "        matchLabels:\n",
    "        app: payment\n",
    "    template:\n",
    "        metadata:\n",
    "        labels:\n",
    "            app: payment\n",
    "        spec:\n",
    "        containers:\n",
    "        - name: payment\n",
    "            image: nginx\n",
    "            ports:\n",
    "            - containerPort: 80\n",
    "\"\"\"\n",
    "\n",
    "@tools\n",
    "def apply_deployment(patch_json: str):\n",
    "    \"\"\"Edit the deployment YAML.\"\"\"\n",
    "    print(\"apply deployment: \", patch_json)\n",
    "    # 这里在后续的课程里会讲解调用 k8s API 来真正部署 patch_json\n",
    "    return \"deployment applied\"\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "tools = [get_deployment, apply_deployment]\n",
    "model_with_tools = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(tools)\n",
    "tool_node = ToolNode(tools)\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"chat\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# 创建图\n",
    "workflow.add_edge(\"__start__\", \"chat\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"chat\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"chat\")\n",
    "app = workflow.compile()\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))\n",
    "\n",
    "for chunk in app.stream(\n",
    "    {\"messages\": [(\"human\", \"帮我修改 payment 的工作负载，镜像为 nginx:v1.0\")]}, stream_mode=\"values\"\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
